{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21812765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d68989",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, groups=1, activation=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False, groups=groups)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=1e-3, momentum=0.03)\n",
    "        self.activation = nn.SiLU(inplace=True) if activation else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(self.bn(self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f70182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, shortcut=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = Conv(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.shortcut = shortcut\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_in = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        if self.shortcut:\n",
    "            x += x_in\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b633ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18944 million parameters\n",
      "Input shape: torch.Size([1, 64, 244, 244]), Output shape: torch.Size([1, 128, 244, 244])\n"
     ]
    }
   ],
   "source": [
    "class C2f(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_bottlenecks, shortcut=True):\n",
    "        super().__init__()\n",
    "        self.mid_channels = out_channels // 2\n",
    "        self.num_bottlenecks = num_bottlenecks\n",
    "\n",
    "        self.conv1 = Conv(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.m = nn.ModuleList([Bottleneck(self.mid_channels, self.mid_channels) for _ in range(num_bottlenecks)])\n",
    "        self.conv2 = Conv((num_bottlenecks + 2)*self.mid_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x1, x2 = x[:, :x.shape[1] // 2, :, :], x[:, x.shape[1] // 2:, :, :]\n",
    "        outputs = [x1, x2]\n",
    "        for i in range(self.num_bottlenecks):\n",
    "            x1 = self.m[i](x1)\n",
    "            outputs.insert(0, x1)\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        out = self.conv2(outputs)\n",
    "        return out\n",
    "\n",
    "c2f = C2f(64, 128, 2)\n",
    "print(f'{sum(p.numel() for p in c2f.parameters())/1e6} million parameters')\n",
    "dummy_input = torch.randn((1, 64, 244, 244))\n",
    "dummy_output = c2f(dummy_input)\n",
    "print(f'Input shape: {dummy_input.shape}, Output shape: {dummy_output.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5f20a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.140416 million parameters\n",
      "Output shape: torch.Size([1, 512, 244, 244])\n"
     ]
    }
   ],
   "source": [
    "class SPPF(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=5):\n",
    "        super().__init__()\n",
    "        hidden_channels = in_channels // 2\n",
    "        self.conv1 = Conv(in_channels, hidden_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv2 = Conv(hidden_channels * 4, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size, stride=1, padding=kernel_size // 2, dilation=1, ceil_mode=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x1 = self.maxpool(x)\n",
    "        x2 = self.maxpool(x1)\n",
    "        x3 = self.maxpool(x2)\n",
    "        x = torch.cat((x, x1, x2, x3), dim=1)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "sppf = SPPF(128, 512)\n",
    "print(f'{sum(p.numel() for p in sppf.parameters())/1e6} million parameters')\n",
    "dummy_output = sppf(dummy_output)\n",
    "print(f'Output shape: {dummy_output.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "797c201c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nano model:\n",
      "1.272656 million parameters\n",
      "Output shapes: torch.Size([1, 64, 80, 80]), torch.Size([1, 128, 40, 40]), torch.Size([1, 256, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "def yolo_params(version):\n",
    "    if version == 'n':\n",
    "        return 1/3, 1/4, 2\n",
    "    elif version == 's':\n",
    "        return 1/3, 1/2, 2\n",
    "    elif version == 'm':\n",
    "        return 2/3, 3/4, 1.5\n",
    "    elif version == 'l':\n",
    "        return 1, 1, 1\n",
    "    elif version == 'x':\n",
    "        return 1, 1.25, 1\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self, version, in_channels=3, shortcut=True):\n",
    "        super().__init__()\n",
    "        d, w, r = yolo_params(version)\n",
    "        self.conv_0 = Conv(in_channels, int(64 * w), kernel_size=3, stride=2, padding=1)\n",
    "        self.conv_1 = Conv(int(64 * w), int(128 * w), kernel_size=3, stride=2, padding=1)\n",
    "        self.conv_3 = Conv(int(128 * w), int(256 * w), kernel_size=3, stride=2, padding=1)\n",
    "        self.conv_5 = Conv(int(256 * w), int(512 * w), kernel_size=3, stride=2, padding=1)\n",
    "        self.conv_7 = Conv(int(512 * w), int(512 * w * r), kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.c2f_2 = C2f(int(128 * w), int(128 * w), num_bottlenecks=int(3 * d), shortcut=True)\n",
    "        self.c2f_4 = C2f(int(256 * w), int(256 * w), num_bottlenecks=int(6 * d), shortcut=True)\n",
    "        self.c2f_6 = C2f(int(512 * w), int(512 * w), num_bottlenecks=int(6 * d), shortcut=True)\n",
    "        self.c2f_8 = C2f(int(512 * w * r), int(512 * w * r), num_bottlenecks=int(3 * d), shortcut=True)\n",
    "\n",
    "        self.sppf = SPPF(int(512 * w * r), int(512 * w * r))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_0(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.c2f_2(x)\n",
    "        x = self.conv_3(x)\n",
    "        out1 = self.c2f_4(x)\n",
    "        x = self.conv_5(out1)\n",
    "        out2 = self.c2f_6(x)\n",
    "        x = self.conv_7(out2)\n",
    "        x = self.c2f_8(x)\n",
    "        x = self.sppf(x)\n",
    "        return out1, out2, x\n",
    "\n",
    "print('Nano model:')\n",
    "backbone_nano = Backbone('n')\n",
    "print(f'{sum(p.numel() for p in backbone_nano.parameters())/1e6} million parameters')\n",
    "x = torch.randn((1, 3, 640, 640))\n",
    "out1, out2, out3 = backbone_nano(x)\n",
    "print(f'Output shapes: {out1.shape}, {out2.shape}, {out3.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f65461f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "    def __init__(self, scale_factor=2, mode='nearest'):\n",
    "        super().__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return nn.functional.interpolate(x, scale_factor=self.scale_factor, mode=self.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38513a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98688 million parameters\n",
      "Output shapes: torch.Size([1, 64, 80, 80]), torch.Size([1, 128, 40, 40]), torch.Size([1, 256, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "class Neck(nn.Module):\n",
    "    def __init__(self, version):\n",
    "        super().__init__()\n",
    "        d, w, r = yolo_params(version)\n",
    "        self.up = Upsample()\n",
    "        self.c2f_1 = C2f(int(512 * w * (1+r)), int(512 * w), num_bottlenecks=int(3 * d), shortcut=False)\n",
    "        self.c2f_2 = C2f(int(768 * w), int(256 * w), num_bottlenecks=int(3 * d), shortcut=False)\n",
    "        self.c2f_3 = C2f(int(768 * w), int(512 * w), num_bottlenecks=int(3 * d), shortcut=False)\n",
    "        self.c2f_4 = C2f(int(512 * w * (1+r)), int(512 * w * r), num_bottlenecks=int(3 * d), shortcut=False)\n",
    "        self.cv_1 = Conv(int(256 * w), int(256 * w), kernel_size=3, stride=2, padding=1)\n",
    "        self.cv_2 = Conv(int(512 * w), int(512 * w), kernel_size=3, stride=2, padding=1)\n",
    "    \n",
    "    def forward(self, x_res_1, x_res_2, x):\n",
    "        res_1 = x\n",
    "        x = self.up(x)\n",
    "        x = torch.cat((x, x_res_2), dim=1)\n",
    "        res_2 = self.c2f_1(x)\n",
    "        x = self.up(res_2)\n",
    "        x = torch.cat((x, x_res_1), dim=1)\n",
    "        out_1 = self.c2f_2(x)\n",
    "        x = self.cv_1(out_1)\n",
    "        x = torch.cat((x, res_2), dim=1)\n",
    "        out_2 = self.c2f_3(x)\n",
    "        x = self.cv_2(out_2)\n",
    "        x = torch.cat((x, res_1), dim=1)\n",
    "        out_3 = self.c2f_4(x)\n",
    "        return out_1, out_2, out_3\n",
    "\n",
    "neck = Neck('n')\n",
    "print(f'{sum(p.numel() for p in neck.parameters())/1e6} million parameters')\n",
    "x = torch.randn((1, 3, 640, 640))\n",
    "out1, out2, out3 = Backbone('n')(x)\n",
    "out_1, out_2, out_3 = neck(out1, out2, out3)\n",
    "print(f'Output shapes: {out_1.shape}, {out_2.shape}, {out_3.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec084364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 parameters\n",
      "Input shape: torch.Size([1, 64, 128]), Output shape: torch.Size([1, 4, 128])\n",
      "DFL(\n",
      "  (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:53] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "class DFL(nn.Module):\n",
    "    def __init__(self, ch=16):\n",
    "        super().__init__()\n",
    "        self.ch = ch\n",
    "        self.conv = nn.Conv2d(in_channels=ch, out_channels=1, kernel_size=1, bias=False).requires_grad_(False)\n",
    "        x = torch.arange(ch, dtype=torch.float).view(1, ch, 1, 1)\n",
    "        self.conv.weight.data[:] = torch.nn.Parameter(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, a = x.shape\n",
    "        x = x.view(b, 4, self.ch, a).transpose(1, 2)\n",
    "        x = x.softmax(1)\n",
    "        x = self.conv(x)\n",
    "        return x.view(b, 4, a)\n",
    "\n",
    "dummy_input = torch.rand((1, 64, 128))\n",
    "dfl = DFL()\n",
    "print(f'{sum(p.numel() for p in dfl.parameters())} parameters')\n",
    "dummy_output = dfl(dummy_input)\n",
    "print(f'Input shape: {dummy_input.shape}, Output shape: {dummy_output.shape}')\n",
    "print(dfl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "056437e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, version, ch=16, num_classes=80):\n",
    "        super().__init__()\n",
    "        self.ch = ch\n",
    "        self.coordinates = self.ch * 4\n",
    "        self.nc = num_classes\n",
    "        self.no = self.coordinates + self.nc\n",
    "        self.stride = torch.zeros(3)\n",
    "        d, w, r = yolo_params(version)\n",
    "\n",
    "        self.box = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                Conv(int(256 * w), self.coordinates, kernel_size=3, stride=1, padding=1),\n",
    "                Conv(self.coordinates, self.coordinates, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(self.coordinates, self.coordinates, kernel_size=1, stride=1)),\n",
    "            nn.Sequential(\n",
    "                Conv(int(512 * w), self.coordinates, kernel_size=3, stride=1, padding=1),\n",
    "                Conv(self.coordinates, self.coordinates, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(self.coordinates, self.coordinates, kernel_size=1, stride=1)),\n",
    "            nn.Sequential(\n",
    "                Conv(int(512 * w * r), self.coordinates, kernel_size=3, stride=1, padding=1),\n",
    "                Conv(self.coordinates, self.coordinates, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(self.coordinates, self.coordinates, kernel_size=1, stride=1))\n",
    "        ])\n",
    "\n",
    "        self.cls = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                Conv(int(256 * w), self.nc, kernel_size=3, stride=1, padding=1),\n",
    "                Conv(self.nc, self.nc, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(self.nc, self.nc, kernel_size=1, stride=1)),\n",
    "            nn.Sequential(\n",
    "                Conv(int(512 * w), self.nc, kernel_size=3, stride=1, padding=1),\n",
    "                Conv(self.nc, self.nc, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(self.nc, self.nc, kernel_size=1, stride=1)),\n",
    "            nn.Sequential(\n",
    "                Conv(int(512 * w * r), self.nc, kernel_size=3, stride=1, padding=1),\n",
    "                Conv(self.nc, self.nc, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(self.nc, self.nc, kernel_size=1, stride=1))\n",
    "        ])\n",
    "\n",
    "        self.dfl = DFL()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.box)):\n",
    "            box = self.box[i](x[i])\n",
    "            clas = self.cls[i](x[i])\n",
    "            x[i] = torch.cat((box, clas), dim=1)\n",
    "                \n",
    "        if self.training:\n",
    "            return x\n",
    "        \n",
    "        anchors, strides = (i.transpose(0, 1) for i in self.make_anchors(x, self.stride))\n",
    "        x = torch.cat([i.view(x[0].shape[0], self.no, -1) for i in x], dim=2)\n",
    "        box, clas = x.split(split_size=(4 * self.ch, self.nc), dim=1)\n",
    "        a, b = self.dfl(box).chunk(2, 1)\n",
    "        a = anchors.unsqueeze(0) - a\n",
    "        b = anchors.unsqueeze(0) + b\n",
    "        box = torch.cat(tensors=((a + b) / 2, (b - a)), dim=1)\n",
    "        return torch.cat(tensors=(box * strides, clas.sigmoid()), dim=1)\n",
    "    \n",
    "    def make_anchors(self, x, strides, offset=0.5):\n",
    "        assert x is not None\n",
    "        anchor_tensor, stride_tensor = [], []\n",
    "        dtype, device = x[0].dtype, x[0].device\n",
    "        for i, stride in enumerate(strides):\n",
    "            _, __, h, w = x[i].shape\n",
    "            sx = torch.arange(end=w, dtype=dtype, device=device) + offset\n",
    "            sy = torch.arange(end=h, dtype=dtype, device=device) + offset\n",
    "            sy, sx = torch.meshgrid(sy, sx)\n",
    "            anchor_tensor.append(torch.stack((sx, sy), -1).view(-1, 2))\n",
    "            stride_tensor.append(torch.full((h * w, 1), stride, dtype=dtype, device=device))\n",
    "        \n",
    "        return torch.cat(anchor_tensor), torch.cat(stride_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bafa416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.897664 million parameters\n",
      "Output shape: torch.Size([1, 144, 80, 80]), torch.Size([1, 144, 40, 40]), torch.Size([1, 144, 20, 20])\n",
      "Head(\n",
      "  (box): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (cls): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (dfl): DFL(\n",
      "    (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "detect = Head('n')\n",
    "print(f'{sum(p.numel() for p in detect.parameters())/1e6} million parameters')\n",
    "output = detect([out_1, out_2, out_3])\n",
    "print(f'Output shape: {output[0].shape}, {output[1].shape}, {output[2].shape}')\n",
    "print(detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b08501a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1572 million parameters\n",
      "Yolo(\n",
      "  (backbone): Backbone(\n",
      "    (conv_0): Conv(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (activation): SiLU(inplace=True)\n",
      "    )\n",
      "    (conv_1): Conv(\n",
      "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (activation): SiLU(inplace=True)\n",
      "    )\n",
      "    (conv_3): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (activation): SiLU(inplace=True)\n",
      "    )\n",
      "    (conv_5): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (activation): SiLU(inplace=True)\n",
      "    )\n",
      "    (conv_7): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (activation): SiLU(inplace=True)\n",
      "    )\n",
      "    (c2f_2): C2f(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (c2f_4): C2f(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (c2f_6): C2f(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (c2f_8): C2f(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (sppf): SPPF(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (maxpool): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (neck): Neck(\n",
      "    (up): Upsample()\n",
      "    (c2f_1): C2f(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (c2f_2): C2f(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (c2f_3): C2f(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (c2f_4): C2f(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (activation): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (activation): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (cv_1): Conv(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (activation): SiLU(inplace=True)\n",
      "    )\n",
      "    (cv_2): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (activation): SiLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (head): Head(\n",
      "    (box): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (activation): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (activation): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv(\n",
      "          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (activation): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (activation): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv(\n",
      "          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (activation): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (activation): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (cls): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv(\n",
      "          (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (activation): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv(\n",
      "          (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (activation): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv(\n",
      "          (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (activation): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv(\n",
      "          (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (activation): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv(\n",
      "          (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (activation): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv(\n",
      "          (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (activation): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (dfl): DFL(\n",
      "      (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Yolo(nn.Module):\n",
    "    def __init__(self, version):\n",
    "        super().__init__()\n",
    "        self.backbone = Backbone(version)\n",
    "        self.neck = Neck(version)\n",
    "        self.head = Head(version)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.neck(x[0], x[1], x[2])\n",
    "        return self.head(list(x))\n",
    "\n",
    "model = Yolo('n')\n",
    "print(f'{sum(p.numel() for p in model.parameters())/1e6} million parameters')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1de5e968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "\n",
    "FORMATS = 'bmp', 'dng', 'jpeg', 'jpg', 'mpo', 'png', 'tif', 'tiff', 'webp'\n",
    "\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, filenames, input_size, params, augment):\n",
    "        self.params = params\n",
    "        self.mosaic = augment\n",
    "        self.augment = augment\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # Read labels\n",
    "        labels = self.load_label(filenames)\n",
    "        self.labels = list(labels.values())\n",
    "        self.filenames = list(labels.keys())  # update\n",
    "        self.n = len(self.filenames)  # number of samples\n",
    "        self.indices = range(self.n)\n",
    "        # Albumentations (optional, only used if package is installed)\n",
    "        self.albumentations = Albumentations()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.indices[index]\n",
    "\n",
    "        params = self.params\n",
    "        mosaic = self.mosaic and random.random() < params['mosaic']\n",
    "\n",
    "        if mosaic:\n",
    "            # Load MOSAIC\n",
    "            image, label = self.load_mosaic(index, params)\n",
    "            # MixUp augmentation\n",
    "            if random.random() < params['mix_up']:\n",
    "                index = random.choice(self.indices)\n",
    "                mix_image1, mix_label1 = image, label\n",
    "                mix_image2, mix_label2 = self.load_mosaic(index, params)\n",
    "\n",
    "                image, label = mix_up(mix_image1, mix_label1, mix_image2, mix_label2)\n",
    "        else:\n",
    "            # Load image\n",
    "            image, shape = self.load_image(index)\n",
    "            h, w = image.shape[:2]\n",
    "\n",
    "            # Resize\n",
    "            image, ratio, pad = resize(image, self.input_size, self.augment)\n",
    "\n",
    "            label = self.labels[index].copy()\n",
    "            if label.size:\n",
    "                label[:, 1:] = wh2xy(label[:, 1:], ratio[0] * w, ratio[1] * h, pad[0], pad[1])\n",
    "            if self.augment:\n",
    "                image, label = random_perspective(image, label, params)\n",
    "\n",
    "        nl = len(label)  # number of labels\n",
    "        h, w = image.shape[:2]\n",
    "        cls = label[:, 0:1]\n",
    "        box = label[:, 1:5]\n",
    "        box = xy2wh(box, w, h)\n",
    "\n",
    "        if self.augment:\n",
    "            # Albumentations\n",
    "            image, box, cls = self.albumentations(image, box, cls)\n",
    "            nl = len(box)  # update after albumentations\n",
    "            # HSV color-space\n",
    "            augment_hsv(image, params)\n",
    "            # Flip up-down\n",
    "            if random.random() < params['flip_ud']:\n",
    "                image = numpy.flipud(image)\n",
    "                if nl:\n",
    "                    box[:, 1] = 1 - box[:, 1]\n",
    "            # Flip left-right\n",
    "            if random.random() < params['flip_lr']:\n",
    "                image = numpy.fliplr(image)\n",
    "                if nl:\n",
    "                    box[:, 0] = 1 - box[:, 0]\n",
    "\n",
    "        target_cls = torch.zeros((nl, 1))\n",
    "        target_box = torch.zeros((nl, 4))\n",
    "        if nl:\n",
    "            target_cls = torch.from_numpy(cls)\n",
    "            target_box = torch.from_numpy(box)\n",
    "\n",
    "        # Convert HWC to CHW, BGR to RGB\n",
    "        sample = image.transpose((2, 0, 1))[::-1]\n",
    "        sample = numpy.ascontiguousarray(sample)\n",
    "\n",
    "        return torch.from_numpy(sample), target_cls, target_box, torch.zeros(nl)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def load_image(self, i):\n",
    "        image = cv2.imread(self.filenames[i])\n",
    "        h, w = image.shape[:2]\n",
    "        r = self.input_size / max(h, w)\n",
    "        if r != 1:\n",
    "            image = cv2.resize(image,\n",
    "                               dsize=(int(w * r), int(h * r)),\n",
    "                               interpolation=resample() if self.augment else cv2.INTER_LINEAR)\n",
    "        return image, (h, w)\n",
    "\n",
    "    def load_mosaic(self, index, params):\n",
    "        label4 = []\n",
    "        border = [-self.input_size // 2, -self.input_size // 2]\n",
    "        image4 = numpy.full((self.input_size * 2, self.input_size * 2, 3), 0, dtype=numpy.uint8)\n",
    "        y1a, y2a, x1a, x2a, y1b, y2b, x1b, x2b = (None, None, None, None, None, None, None, None)\n",
    "\n",
    "        xc = int(random.uniform(-border[0], 2 * self.input_size + border[1]))\n",
    "        yc = int(random.uniform(-border[0], 2 * self.input_size + border[1]))\n",
    "\n",
    "        indices = [index] + random.choices(self.indices, k=3)\n",
    "        random.shuffle(indices)\n",
    "\n",
    "        for i, index in enumerate(indices):\n",
    "            # Load image\n",
    "            image, _ = self.load_image(index)\n",
    "            shape = image.shape\n",
    "            if i == 0:  # top left\n",
    "                x1a = max(xc - shape[1], 0)\n",
    "                y1a = max(yc - shape[0], 0)\n",
    "                x2a = xc\n",
    "                y2a = yc\n",
    "                x1b = shape[1] - (x2a - x1a)\n",
    "                y1b = shape[0] - (y2a - y1a)\n",
    "                x2b = shape[1]\n",
    "                y2b = shape[0]\n",
    "            if i == 1:  # top right\n",
    "                x1a = xc\n",
    "                y1a = max(yc - shape[0], 0)\n",
    "                x2a = min(xc + shape[1], self.input_size * 2)\n",
    "                y2a = yc\n",
    "                x1b = 0\n",
    "                y1b = shape[0] - (y2a - y1a)\n",
    "                x2b = min(shape[1], x2a - x1a)\n",
    "                y2b = shape[0]\n",
    "            if i == 2:  # bottom left\n",
    "                x1a = max(xc - shape[1], 0)\n",
    "                y1a = yc\n",
    "                x2a = xc\n",
    "                y2a = min(self.input_size * 2, yc + shape[0])\n",
    "                x1b = shape[1] - (x2a - x1a)\n",
    "                y1b = 0\n",
    "                x2b = shape[1]\n",
    "                y2b = min(y2a - y1a, shape[0])\n",
    "            if i == 3:  # bottom right\n",
    "                x1a = xc\n",
    "                y1a = yc\n",
    "                x2a = min(xc + shape[1], self.input_size * 2)\n",
    "                y2a = min(self.input_size * 2, yc + shape[0])\n",
    "                x1b = 0\n",
    "                y1b = 0\n",
    "                x2b = min(shape[1], x2a - x1a)\n",
    "                y2b = min(y2a - y1a, shape[0])\n",
    "\n",
    "            pad_w = x1a - x1b\n",
    "            pad_h = y1a - y1b\n",
    "            image4[y1a:y2a, x1a:x2a] = image[y1b:y2b, x1b:x2b]\n",
    "\n",
    "            # Labels\n",
    "            label = self.labels[index].copy()\n",
    "            if len(label):\n",
    "                label[:, 1:] = wh2xy(label[:, 1:], shape[1], shape[0], pad_w, pad_h)\n",
    "            label4.append(label)\n",
    "\n",
    "        # Concat/clip labels\n",
    "        label4 = numpy.concatenate(label4, 0)\n",
    "        for x in label4[:, 1:]:\n",
    "            numpy.clip(x, 0, 2 * self.input_size, out=x)\n",
    "\n",
    "        # Augment\n",
    "        image4, label4 = random_perspective(image4, label4, params, border)\n",
    "\n",
    "        return image4, label4\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        samples, cls, box, indices = zip(*batch)\n",
    "\n",
    "        cls = torch.cat(cls, dim=0)\n",
    "        box = torch.cat(box, dim=0)\n",
    "\n",
    "        new_indices = list(indices)\n",
    "        for i in range(len(indices)):\n",
    "            new_indices[i] += i\n",
    "        indices = torch.cat(new_indices, dim=0)\n",
    "\n",
    "        targets = {'cls': cls,\n",
    "                   'box': box,\n",
    "                   'idx': indices}\n",
    "        return torch.stack(samples, dim=0), targets\n",
    "\n",
    "    @staticmethod\n",
    "    def load_label(filenames):\n",
    "        path = f'{os.path.dirname(filenames[0])}.cache'\n",
    "        if os.path.exists(path):\n",
    "            return torch.load(path)\n",
    "        x = {}\n",
    "        for filename in filenames:\n",
    "            try:\n",
    "                # verify images\n",
    "                with open(filename, 'rb') as f:\n",
    "                    image = Image.open(f)\n",
    "                    image.verify()  # PIL verify\n",
    "                shape = image.size  # image size\n",
    "                assert (shape[0] > 9) & (shape[1] > 9), f'image size {shape} <10 pixels'\n",
    "                assert image.format.lower() in FORMATS, f'invalid image format {image.format}'\n",
    "\n",
    "                # verify labels\n",
    "                a = f'{os.sep}images{os.sep}'\n",
    "                b = f'{os.sep}labels{os.sep}'\n",
    "                if os.path.isfile(b.join(filename.rsplit(a, 1)).rsplit('.', 1)[0] + '.txt'):\n",
    "                    with open(b.join(filename.rsplit(a, 1)).rsplit('.', 1)[0] + '.txt') as f:\n",
    "                        label = [x.split() for x in f.read().strip().splitlines() if len(x)]\n",
    "                        label = numpy.array(label, dtype=numpy.float32)\n",
    "                    nl = len(label)\n",
    "                    if nl:\n",
    "                        assert (label >= 0).all()\n",
    "                        assert label.shape[1] == 5\n",
    "                        assert (label[:, 1:] <= 1).all()\n",
    "                        _, i = numpy.unique(label, axis=0, return_index=True)\n",
    "                        if len(i) < nl:  # duplicate row check\n",
    "                            label = label[i]  # remove duplicates\n",
    "                    else:\n",
    "                        label = numpy.zeros((0, 5), dtype=numpy.float32)\n",
    "                else:\n",
    "                    label = numpy.zeros((0, 5), dtype=numpy.float32)\n",
    "            except FileNotFoundError:\n",
    "                label = numpy.zeros((0, 5), dtype=numpy.float32)\n",
    "            except AssertionError:\n",
    "                continue\n",
    "            x[filename] = label\n",
    "        torch.save(x, path)\n",
    "        return x\n",
    "\n",
    "\n",
    "def wh2xy(x, w=640, h=640, pad_w=0, pad_h=0):\n",
    "    # Convert nx4 boxes\n",
    "    # from [x, y, w, h] normalized to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n",
    "    y = numpy.copy(x)\n",
    "    y[:, 0] = w * (x[:, 0] - x[:, 2] / 2) + pad_w  # top left x\n",
    "    y[:, 1] = h * (x[:, 1] - x[:, 3] / 2) + pad_h  # top left y\n",
    "    y[:, 2] = w * (x[:, 0] + x[:, 2] / 2) + pad_w  # bottom right x\n",
    "    y[:, 3] = h * (x[:, 1] + x[:, 3] / 2) + pad_h  # bottom right y\n",
    "    return y\n",
    "\n",
    "\n",
    "def xy2wh(x, w, h):\n",
    "    # warning: inplace clip\n",
    "    x[:, [0, 2]] = x[:, [0, 2]].clip(0, w - 1E-3)  # x1, x2\n",
    "    x[:, [1, 3]] = x[:, [1, 3]].clip(0, h - 1E-3)  # y1, y2\n",
    "\n",
    "    # Convert nx4 boxes\n",
    "    # from [x1, y1, x2, y2] to [x, y, w, h] normalized where xy1=top-left, xy2=bottom-right\n",
    "    y = numpy.copy(x)\n",
    "    y[:, 0] = ((x[:, 0] + x[:, 2]) / 2) / w  # x center\n",
    "    y[:, 1] = ((x[:, 1] + x[:, 3]) / 2) / h  # y center\n",
    "    y[:, 2] = (x[:, 2] - x[:, 0]) / w  # width\n",
    "    y[:, 3] = (x[:, 3] - x[:, 1]) / h  # height\n",
    "    return y\n",
    "\n",
    "\n",
    "def resample():\n",
    "    choices = (cv2.INTER_AREA,\n",
    "               cv2.INTER_CUBIC,\n",
    "               cv2.INTER_LINEAR,\n",
    "               cv2.INTER_NEAREST,\n",
    "               cv2.INTER_LANCZOS4)\n",
    "    return random.choice(seq=choices)\n",
    "\n",
    "\n",
    "def augment_hsv(image, params):\n",
    "    # HSV color-space augmentation\n",
    "    h = params['hsv_h']\n",
    "    s = params['hsv_s']\n",
    "    v = params['hsv_v']\n",
    "\n",
    "    r = numpy.random.uniform(-1, 1, 3) * [h, s, v] + 1\n",
    "    h, s, v = cv2.split(cv2.cvtColor(image, cv2.COLOR_BGR2HSV))\n",
    "\n",
    "    x = numpy.arange(0, 256, dtype=r.dtype)\n",
    "    lut_h = ((x * r[0]) % 180).astype('uint8')\n",
    "    lut_s = numpy.clip(x * r[1], 0, 255).astype('uint8')\n",
    "    lut_v = numpy.clip(x * r[2], 0, 255).astype('uint8')\n",
    "\n",
    "    hsv = cv2.merge((cv2.LUT(h, lut_h), cv2.LUT(s, lut_s), cv2.LUT(v, lut_v)))\n",
    "    cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR, dst=image)  # no return needed\n",
    "\n",
    "\n",
    "def resize(image, input_size, augment):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = image.shape[:2]  # current shape [height, width]\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(input_size / shape[0], input_size / shape[1])\n",
    "    if not augment:  # only scale down, do not scale up (for better val mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    pad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    w = (input_size - pad[0]) / 2\n",
    "    h = (input_size - pad[1]) / 2\n",
    "\n",
    "    if shape[::-1] != pad:  # resize\n",
    "        image = cv2.resize(image,\n",
    "                           dsize=pad,\n",
    "                           interpolation=resample() if augment else cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(h - 0.1)), int(round(h + 0.1))\n",
    "    left, right = int(round(w - 0.1)), int(round(w + 0.1))\n",
    "    image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT)  # add border\n",
    "    return image, (r, r), (w, h)\n",
    "\n",
    "\n",
    "def candidates(box1, box2):\n",
    "    # box1(4,n), box2(4,n)\n",
    "    w1, h1 = box1[2] - box1[0], box1[3] - box1[1]\n",
    "    w2, h2 = box2[2] - box2[0], box2[3] - box2[1]\n",
    "    aspect_ratio = numpy.maximum(w2 / (h2 + 1e-16), h2 / (w2 + 1e-16))  # aspect ratio\n",
    "    return (w2 > 2) & (h2 > 2) & (w2 * h2 / (w1 * h1 + 1e-16) > 0.1) & (aspect_ratio < 100)\n",
    "\n",
    "\n",
    "def random_perspective(image, label, params, border=(0, 0)):\n",
    "    h = image.shape[0] + border[0] * 2\n",
    "    w = image.shape[1] + border[1] * 2\n",
    "\n",
    "    # Center\n",
    "    center = numpy.eye(3)\n",
    "    center[0, 2] = -image.shape[1] / 2  # x translation (pixels)\n",
    "    center[1, 2] = -image.shape[0] / 2  # y translation (pixels)\n",
    "\n",
    "    # Perspective\n",
    "    perspective = numpy.eye(3)\n",
    "\n",
    "    # Rotation and Scale\n",
    "    rotate = numpy.eye(3)\n",
    "    a = random.uniform(-params['degrees'], params['degrees'])\n",
    "    s = random.uniform(1 - params['scale'], 1 + params['scale'])\n",
    "    rotate[:2] = cv2.getRotationMatrix2D(angle=a, center=(0, 0), scale=s)\n",
    "\n",
    "    # Shear\n",
    "    shear = numpy.eye(3)\n",
    "    shear[0, 1] = math.tan(random.uniform(-params['shear'], params['shear']) * math.pi / 180)\n",
    "    shear[1, 0] = math.tan(random.uniform(-params['shear'], params['shear']) * math.pi / 180)\n",
    "\n",
    "    # Translation\n",
    "    translate = numpy.eye(3)\n",
    "    translate[0, 2] = random.uniform(0.5 - params['translate'], 0.5 + params['translate']) * w\n",
    "    translate[1, 2] = random.uniform(0.5 - params['translate'], 0.5 + params['translate']) * h\n",
    "\n",
    "    # Combined rotation matrix, order of operations (right to left) is IMPORTANT\n",
    "    matrix = translate @ shear @ rotate @ perspective @ center\n",
    "    if (border[0] != 0) or (border[1] != 0) or (matrix != numpy.eye(3)).any():  # image changed\n",
    "        image = cv2.warpAffine(image, matrix[:2], dsize=(w, h), borderValue=(0, 0, 0))\n",
    "\n",
    "    # Transform label coordinates\n",
    "    n = len(label)\n",
    "    if n:\n",
    "        xy = numpy.ones((n * 4, 3))\n",
    "        xy[:, :2] = label[:, [1, 2, 3, 4, 1, 4, 3, 2]].reshape(n * 4, 2)  # x1y1, x2y2, x1y2, x2y1\n",
    "        xy = xy @ matrix.T  # transform\n",
    "        xy = xy[:, :2].reshape(n, 8)  # perspective rescale or affine\n",
    "\n",
    "        # create new boxes\n",
    "        x = xy[:, [0, 2, 4, 6]]\n",
    "        y = xy[:, [1, 3, 5, 7]]\n",
    "        box = numpy.concatenate((x.min(1), y.min(1), x.max(1), y.max(1))).reshape(4, n).T\n",
    "\n",
    "        # clip\n",
    "        box[:, [0, 2]] = box[:, [0, 2]].clip(0, w)\n",
    "        box[:, [1, 3]] = box[:, [1, 3]].clip(0, h)\n",
    "        # filter candidates\n",
    "        indices = candidates(box1=label[:, 1:5].T * s, box2=box.T)\n",
    "\n",
    "        label = label[indices]\n",
    "        label[:, 1:5] = box[indices]\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def mix_up(image1, label1, image2, label2):\n",
    "    # Applies MixUp augmentation https://arxiv.org/pdf/1710.09412.pdf\n",
    "    alpha = numpy.random.beta(a=32.0, b=32.0)  # mix-up ratio, alpha=beta=32.0\n",
    "    image = (image1 * alpha + image2 * (1 - alpha)).astype(numpy.uint8)\n",
    "    label = numpy.concatenate((label1, label2), 0)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "class Albumentations:\n",
    "    def __init__(self):\n",
    "        self.transform = None\n",
    "        try:\n",
    "            import albumentations\n",
    "\n",
    "            transforms = [albumentations.Blur(p=0.01),\n",
    "                          albumentations.CLAHE(p=0.01),\n",
    "                          albumentations.ToGray(p=0.01),\n",
    "                          albumentations.MedianBlur(p=0.01)]\n",
    "            self.transform = albumentations.Compose(transforms,\n",
    "                                                    albumentations.BboxParams('yolo', ['class_labels']))\n",
    "\n",
    "        except ImportError:  # package not installed, skip\n",
    "            pass\n",
    "\n",
    "    def __call__(self, image, box, cls):\n",
    "        if self.transform:\n",
    "            x = self.transform(image=image,\n",
    "                               bboxes=box,\n",
    "                               class_labels=cls)\n",
    "            image = x['image']\n",
    "            box = numpy.array(x['bboxes'])\n",
    "            cls = numpy.array(x['class_labels'])\n",
    "        return image, box, cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd994191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loader : 1849 batches\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from torch.utils import data\n",
    "\n",
    "# get all file names\n",
    "data_dir= 'COCO'\n",
    "filenames_train = []\n",
    "with open(f'train2017.txt') as reader:\n",
    "    for filename in reader.readlines():\n",
    "        filename = os.path.basename(filename.rstrip())\n",
    "        filenames_train.append(f'{data_dir}/images/train2017/' + filename)\n",
    "\n",
    "# input_size for the model\n",
    "input_size=640\n",
    "\n",
    "# get params from yaml file\n",
    "with open('args.yaml', errors='ignore') as f:\n",
    "        params = yaml.safe_load(f)\n",
    "\n",
    "train_data=Dataset(filenames_train,input_size,params,augment=True)\n",
    "train_loader = data.DataLoader(train_data, batch_size=64, num_workers=0, pin_memory=True, collate_fn=Dataset.collate_fn)\n",
    "print(f\"Train_loader : {len(train_loader)} batches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecb7ff0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1679.675] global loadsave.cpp:268 findDecoder imread_('COCO/images/train2017/000000109622.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll keys in batch      : \u001b[39m\u001b[38;5;124m\"\u001b[39m, batch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput batch shape      : \u001b[39m\u001b[38;5;124m\"\u001b[39m, batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[16], line 38\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     34\u001b[0m mosaic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmosaic \u001b[38;5;129;01mand\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmosaic\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mosaic:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# Load MOSAIC\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     image, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_mosaic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# MixUp augmentation\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmix_up\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[16], line 122\u001b[0m, in \u001b[0;36mDataset.load_mosaic\u001b[0;34m(self, index, params)\u001b[0m\n\u001b[1;32m    118\u001b[0m random\u001b[38;5;241m.\u001b[39mshuffle(indices)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(indices):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# Load image\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     image, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     shape \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# top left\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 100\u001b[0m, in \u001b[0;36mDataset.load_image\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_image\u001b[39m(\u001b[38;5;28mself\u001b[39m, i):\n\u001b[1;32m     99\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilenames[i])\n\u001b[0;32m--> 100\u001b[0m     h, w \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    101\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mmax\u001b[39m(h, w)\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "batch=next(iter(train_loader))\n",
    "print(\"All keys in batch      : \", batch[1].keys())\n",
    "print(f\"Input batch shape      : \", batch[0].shape)\n",
    "print(f\"Classification scores  : {batch[1]['cls'].shape}\")\n",
    "print(f\"Box coordinates        : {batch[1]['box'].shape}\")\n",
    "print(f\"Index identifier (which score belongs to which image): {batch[1]['idx'].shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
